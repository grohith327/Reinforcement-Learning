{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnv:\n",
    "    def __init__(self, m=3, n=4, gamma=0.9):\n",
    "        self.m = m\n",
    "        self.n = n\n",
    "        self.grid = None\n",
    "        self.wall = (m // 2, n // 2 - 1)\n",
    "        self.goal = (0, n - 1)\n",
    "        self.pit = (1, n - 1)\n",
    "        self.gamma = gamma\n",
    "        self.reset()\n",
    "\n",
    "        self.action_map = {\n",
    "            0: \"↑\",\n",
    "            1: \"→\",\n",
    "            2: \"↓\",\n",
    "            3: \"←\",\n",
    "        }\n",
    "        self.policy = None\n",
    "        self.Q = None\n",
    "\n",
    "    def reset(self):\n",
    "        self.grid = [[0] * self.n for _ in range(self.m)]\n",
    "        self.grid = np.array(self.grid).astype(np.float)\n",
    "        self.grid[self.goal[0], self.goal[1]] = 1\n",
    "        self.grid[1, -1] = -1\n",
    "\n",
    "    def render(self, values=None):\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.gcf().canvas.mpl_connect(\n",
    "            \"key_release_event\",\n",
    "            lambda event: [exit(0) if event.key == \"escape\" else None],\n",
    "        )\n",
    "        ax.imshow(self.grid, cmap=cm.get_cmap(\"YlGn\"))\n",
    "        ax.grid(True, which=\"major\", axis=\"both\")\n",
    "        ax.set_xticks(np.arange(-0.5, self.n, 1))\n",
    "        ax.set_yticks(np.arange(-0.5, self.m, 1))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "        x_start = -0.5\n",
    "        x_end = self.n\n",
    "        y_start = -0.5\n",
    "        y_end = self.m\n",
    "\n",
    "        jump_x = (x_end - x_start) / (2.0 * self.n)\n",
    "        jump_y = (y_end - y_start) / (2.0 * self.m)\n",
    "        x_positions = np.linspace(start=x_start, stop=x_end, num=self.n, endpoint=False)\n",
    "        y_positions = np.linspace(start=y_start, stop=y_end, num=self.m, endpoint=False)\n",
    "\n",
    "        for y_index, y in enumerate(y_positions):\n",
    "            for x_index, x in enumerate(x_positions):\n",
    "                if self.wall == (x_index, y_index):\n",
    "                    continue\n",
    "                if values is None:\n",
    "                    label = self.action_map[self.policy[y_index, x_index]]\n",
    "                else:\n",
    "                    label = str(round(values[y_index][x_index], 2))\n",
    "                if (y_index, x_index) == self.pit:\n",
    "                    label = -1\n",
    "                if (y_index, x_index) == self.goal:\n",
    "                    label = 1\n",
    "                text_x = x + jump_x * 0.5\n",
    "                text_y = y + jump_y * 0.5\n",
    "                ax.text(text_x, text_y, label, color=\"black\", ha=\"center\", va=\"center\")\n",
    "\n",
    "        plt.pause(0.1)\n",
    "        _ = plt.show()\n",
    "\n",
    "    def step(self, curr_state, action):\n",
    "        assert action <= 3 and action >= 0, \"action out of range\"\n",
    "\n",
    "        m = self.m\n",
    "        n = self.n\n",
    "        rand = np.random.rand()\n",
    "\n",
    "        if action == 0:\n",
    "            if rand <= 0.8:\n",
    "                state = (max(curr_state[0] - 1, 0), curr_state[1])\n",
    "            elif rand > 0.8 and rand <= 0.9:\n",
    "                state = (curr_state[0], max(curr_state[1] - 1, 0))\n",
    "            else:\n",
    "                state = (curr_state[0], min(curr_state[1] + 1, n - 1))\n",
    "\n",
    "        if action == 1:\n",
    "            if rand <= 0.8:\n",
    "                state = (curr_state[0], min(curr_state[1] + 1, n - 1))\n",
    "            elif rand > 0.8 and rand <= 0.9:\n",
    "                state = (max(curr_state[0] - 1, 0), curr_state[1])\n",
    "            else:\n",
    "                state = (min(curr_state[0] + 1, m - 1), curr_state[1])\n",
    "\n",
    "        if action == 2:\n",
    "            if rand <= 0.8:\n",
    "                state = (min(curr_state[0] + 1, m - 1), curr_state[1])\n",
    "            elif rand > 0.8 and rand <= 0.9:\n",
    "                state = (curr_state[0], max(curr_state[1] - 1, 0))\n",
    "            else:\n",
    "                state = (curr_state[0], min(curr_state[1] + 1, n - 1))\n",
    "\n",
    "        if action == 3:\n",
    "            if rand <= 0.8:\n",
    "                state = (curr_state[0], max(curr_state[1] - 1, 0))\n",
    "            elif rand > 0.8 and rand <= 0.9:\n",
    "                state = (max(curr_state[0] - 1, 0), curr_state[1])\n",
    "            else:\n",
    "                state = (min(curr_state[0] + 1, m - 1), curr_state[1])\n",
    "\n",
    "        if state == self.wall:\n",
    "            state = curr_state\n",
    "\n",
    "        done = False\n",
    "        reward = 0\n",
    "        if state in [self.pit, self.goal]:\n",
    "            done = True\n",
    "            reward = -1 if state == self.pit else 1\n",
    "\n",
    "        return state, reward, done\n",
    "\n",
    "    def get_qvalues(self):\n",
    "        Q = {(i, j): np.random.rand(4) for i in range(self.m) for j in range(self.n)}\n",
    "        return Q\n",
    "\n",
    "    def get_policy(self, Q):\n",
    "        policy = [[0] * self.n for _ in range(self.m)]\n",
    "        for k, v in Q.items():\n",
    "            policy[k[0]][k[1]] = np.argmax(v)\n",
    "        return np.array(policy)\n",
    "\n",
    "    def get_action(self, Q, state, eps):\n",
    "        if np.random.rand() <= 1.0 - eps:\n",
    "            return np.argmax(Q[state])\n",
    "        return np.random.randint(4)\n",
    "\n",
    "    def SARSA(\n",
    "        self, episodes=10, rollout_steps=50, alpha=0.85, eps=0.2, Q=None, render=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        On Policy TD Control\n",
    "        -> Epsilon greedy policy\n",
    "        \"\"\"\n",
    "        self.Q = Q\n",
    "        if Q is None:\n",
    "            self.Q = self.get_qvalues()\n",
    "\n",
    "        self.policy = self.get_policy(self.Q)\n",
    "        if render:\n",
    "            print(\"Current policy\")\n",
    "            self.render()\n",
    "\n",
    "        for e in tqdm(range(episodes)):\n",
    "            state = (np.random.randint(self.m), np.random.randint(self.n))\n",
    "            while state in [self.pit, self.wall, self.goal]:\n",
    "                state = (np.random.randint(self.m), np.random.randint(self.n))\n",
    "            action = self.get_action(self.Q, state, eps)\n",
    "            for step in range(rollout_steps):\n",
    "                new_state, reward, done = self.step(state, action)\n",
    "                new_action = self.get_action(self.Q, new_state, eps)\n",
    "                q_update = self.Q[state][action] + alpha * (\n",
    "                    reward\n",
    "                    + self.gamma * self.Q[new_state][new_action]\n",
    "                    - self.Q[state][action]\n",
    "                )\n",
    "                self.Q[state][action] = q_update\n",
    "                state = new_state\n",
    "                action = new_action\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            self.policy = self.get_policy(self.Q)\n",
    "            if render:\n",
    "                print(\"Episode: {}/{}\".format(e + 1, episodes))\n",
    "                self.render()\n",
    "\n",
    "        return self.policy, self.Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 7066.72it/s]\n"
     ]
    }
   ],
   "source": [
    "## Start with random Q Values / Policy\n",
    "policy, Q = env.SARSA(episodes=10000, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Final Policy\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
